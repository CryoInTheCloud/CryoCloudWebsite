{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICESat-2 and Landsat cloud access and data integration\n",
    "\n",
    "This notebook ({nb-download}`download <IS2_cloud_data_integration.ipynb>`) builds off of the icepyx [IS2_cloud_data_access.ipynb](https://icepyx.readthedocs.io/en/latest/example_notebooks/IS2_cloud_data_access.html) and [ICESat-2 Hackweek Data Integration 1](https://icesat-2.hackweek.io/tutorials/DataIntegration/dataintegration-1.html) tutorials. It illustrates the use of icepyx for accessing ICESat-2 data currently available through the AWS (Amazon Web Services) us-west2 hub s3 data bucket as well as data integration with Landsat (cloud-optimized geotiff) and ATM (downloaded csv) datasets.\n",
    "\n",
    "```{admonition} Learning Objectives\n",
    "**Goals**\n",
    "- Identify and locate ICESat-2 and Landsat data\n",
    "- Acquire data from the cloud\n",
    "- Open data in `pandas` and `xarray` and basic functioning of DataFrames\n",
    "```\n",
    "\n",
    "```{admonition} Key Takeaway\n",
    "By the end of this tutorial, you will be able to visualize Landsat Cloud Optimized Geotiffs with ICESat-2 and ATM data.\n",
    "```\n",
    "\n",
    "## Notes\n",
    "1. ICESat-2 data became publicly available on the cloud on 29 September 2022. Thus, access methods and example workflows are still being developed by NSIDC, and the underlying code in icepyx will need to be updated now that these data (and the associated metadata) are available. We appreciate your patience and contributions (e.g. reporting bugs, sharing your code, etc.) during this transition!\n",
    "2. This example and the code it describes are part of ongoing development. Current limitations to using these features are described throughout the example, as appropriate.\n",
    "3. You **MUST** be working within an AWS instance. Otherwise, you will get a permissions error.\n",
    "4. Authentication is still more steps than we'd like. We're working to address this - let us know if you'd like to join the conversation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, feel free to run the code along with us as we live code by downsizing the zoom window and splitting your screen (or using two screens). Or you can simply watch the zoom walkthrough. Don't worry if you fall behind on the code. The notebook is standalone and you can easily run the code at your own pace another time to catch anything you missed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing environment\n",
    "\n",
    "We'll be using the following open source Python libraries in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress library deprecation warnings\n",
    "import logging\n",
    "logging.captureWarnings(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "from ipyleaflet import Map, GeoData, LayersControl,Rectangle, basemaps, basemap_to_tiles, TileLayer, SplitMapControl, Polygon\n",
    "\n",
    "import ipywidgets\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pystac_client\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import ast\n",
    "import pandas as pd\n",
    "import geoviews as gv\n",
    "import hvplot.pandas\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, Image\n",
    "import intake # if you've installed intake-STAC, it will automatically import alongside intake\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import rasterio as rio\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.plot import show\n",
    "import rioxarray as rxr\n",
    "from dask.utils import SerializableLock\n",
    "import os\n",
    "import fiona\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "from pyproj import Proj, transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identify and acquire the ICESat2 product(s) of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download ICESat-2 ATL06 data from desired region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use icepyx to download some ICESat-2 ATL06 data over our region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icepyx as ipx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the necessary icepyx parameters\n",
    "short_name = 'ATL06'\n",
    "spatial_extent = 'hackweek_kml_jakobshavan.kml' # KML polygon centered on Sermeq Kujalleq\n",
    "date_range = ['2019-04-01', '2019-04-30']\n",
    "rgts = ['338'] # IS-2 RGT of interest\n",
    "\n",
    "# # bounding box\n",
    "# # \"producerGranuleId\": \"ATL03_20191130221008_09930503_004_01.h5\",\n",
    "# short_name = 'ATL03'\n",
    "# spatial_extent = [-45, 58, -35, 75]\n",
    "# date_range = ['2019-11-30','2019-11-30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that we specified a RGT track. As seen below, a large number of ICESat-2 overpasses occur for Sermeq Kujalleq (briefly known as Jakobshavn Isbrae). In the interest of time (and computer memory), we are going to look at only one of these tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image of area of interest (data viz tutorial will get in deeper so don't explain much):\n",
    "center = [69.2, -50]\n",
    "zoom = 7\n",
    "\n",
    "# Open KML file for visualizing\n",
    "fiona.drvsupport.supported_drivers['LIBKML'] = 'rw' # enable KML support which is disabled by default\n",
    "jk = gpd.read_file(spatial_extent)\n",
    "\n",
    "\n",
    "m = Map(basemap=basemap_to_tiles(basemaps.NASAGIBS.ModisAquaTrueColorCR, '2020-07-18'),center=center,zoom=zoom)\n",
    "geo_data = GeoData(geo_dataframe = jk)\n",
    "\n",
    "m.add_layer(geo_data)\n",
    "m.add_control(LayersControl())\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Query object\n",
    "region = ipx.Query(short_name, spatial_extent, date_range, tracks=rgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region.visualize_spatial_extent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have an ICESat-2 track! Let's quickly visualize the data to ensure that there are no clouds.\n",
    "\n",
    "Note: While preparing this tutorial, we found a bug in the icepyx code (missed after recent changes to spatial information handling to deal with cross-dateline regions). We're in the process of correcting it there, but implemented this inline fix for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotspat_ext = list(region.spatial.extent_as_gdf.geometry.unary_union.minimum_rotated_rectangle.bounds)\n",
    "plotreg = ipx.Query(short_name, plotspat_ext, date_range, tracks=rgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request information from OpenAltimetry\n",
    "cyclemap, rgtmap = plotreg.visualize_elevation()\n",
    "\n",
    "rgtmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now it's time to acquire the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the granule s3 urls\n",
    "You must specify `cloud=True` to get the needed s3 urls.\n",
    "This function returns a list containing the list of the granule IDs and a list of the corresponding urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_ids = region.avail_granules(ids=True, cloud=True)\n",
    "gran_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log in to Earthdata and generate an s3 token\n",
    "You can use icepyx's existing login functionality to generate your s3 data access token, which will be valid for *one* hour.\n",
    "\n",
    "We currently do not have this set up to automatically renew, but [earthaccess](), which icepyx will soon be adopting for authentication, is working on handling the limits imposed by expiring s3 tokens. If you're interested in working on helping icepyx and NSIDC (and DAACs more broadly) address these challenges, please get in touch or submit a PR. Documentation/example testers are always appreciated (so you don't have to understand the code)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "region.earthdata_login(\"tsnow03\",\"tsnow@mines.edu\", s3token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = region._s3login_credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your s3 access using your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(key=credentials['accessKeyId'],\n",
    "                       secret=credentials['secretAccessKey'],\n",
    "                       token=credentials['sessionToken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an s3 url and access the data\n",
    "Data read in capabilities for cloud data are coming soon in icepyx (targeted Winter 2022-2023). Stay tuned and we'd love for you to join us and contribute!\n",
    "\n",
    "**Note: If you get a PermissionDenied Error when trying to read in the data, you may not be sending your request from an AWS hub in us-west2. We're currently working on how to alert users if they will not be able to access ICESat-2 data in the cloud for this reason**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first index, [1], gets us into the list of s3 urls\n",
    "# the second index, [0], gets us the first entry in that list.\n",
    "s3url = gran_ids[1][0]\n",
    "# s3url =  's3://nsidc-cumulus-prod-protected/ATLAS/ATL03/004/2019/11/30/ATL03_20191130221008_09930503_004_01.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "%time f = h5py.File(s3.open(s3url,'rb'),'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View it's attributes\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the file with h5py allows us to open the entire file, but is not super intuitive for later analysis. Let's use h5py with pandas to open the data into DataFrames in a way that is more convenient for our analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ICESat-2 data. We will just look at the central beams (GT2R/L)\n",
    "# is2_file = 'processed_ATL06_20190420093051_03380303_005_01_full.h5'\n",
    "with h5py.File(s3.open(s3url,'rb'), 'r') as f:\n",
    "    is2_gt2r = pd.DataFrame(data={'lat': f['gt2r/land_ice_segments/latitude'][:],\n",
    "                                  'lon': f['gt2r/land_ice_segments/longitude'][:],\n",
    "                                  'elev': f['gt2r/land_ice_segments/h_li'][:]})\n",
    "    is2_gt2l = pd.DataFrame(data={'lat': f['gt2l/land_ice_segments/latitude'][:],\n",
    "                                  'lon': f['gt2l/land_ice_segments/longitude'][:],\n",
    "                                  'elev': f['gt2l/land_ice_segments/h_li'][:]})\n",
    "    \n",
    "is2_gt2r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We opened this data into a `pandas` DataFrame, which is a handy tool for Earth data exploration and analysis. The column names derive automatically from the first row of the csv and each row corresponds to an ATM measurement.\n",
    "\n",
    "For a tutorial on how to use `pandas` on this data, check out the [ICESat-2 Hackweek Data Integration I tutorial](https://icesat-2.hackweek.io/tutorials/DataIntegration/dataintegration-1.html). You can learn more about `pandas` from [this cookbook](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acquire non-cloud data and open:  ATM data access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will show ATM (non-AWS) and Landsat (AWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did we choose April 2019 and RGT 338? In Spring 2019, an airborne campaign called Operation IceBridge was flown across Sermeq Kujalleq as validation for ICESat-2. Onboard was the Airborne Topographic Mapper, a lidar that works at both 532 nm (like ICESat-2) and 1064 nm (near-infrared). More information about Operation IceBridge and ATM may be found here: https://nsidc.org/data/icebridge\n",
    "\n",
    "Here, we are going to try and co-register ATM spot measurements with ICESat-2. Because both data sets are rather large, this can be computationally expensive, so we will only consider one flight track with the ATM 532 nm beam.\n",
    "\n",
    "Operation IceBridge data is not available on the cloud, so this data was downloaded directly from NSIDC. If you are interested in using IceBridge data, NSIDC has a useful data portal here: https://nsidc.org/icebridge/portal/map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-register ICESat-2 with ATM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ATM data into a DataFrame\n",
    "atm_file = 'ILATM2_20190506_151600_smooth_nadir3seg_50pt.csv'\n",
    "atm_l2 = pd.read_csv(atm_file)\n",
    "\n",
    "atm_l2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ATM L2 file contains plenty of information, including surface height estimates and slope of the local topography. It also contains a track identifier - ATM takes measurements from multiple parts of the aircraft, namely starboard, port, and nadir. To keep things simple, we will filter the DataFrame to only look at the nadir track (Track_Identifier = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_l2 = atm_l2[atm_l2['Track_Identifier']==0]\n",
    "\n",
    "# Change the longitudes to be consistent with ICESat-2\n",
    "atm_l2['Longitude(deg)'] -= 360\n",
    "\n",
    "print(atm_l2.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at where ATM is relative to ICESat-2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the ICESat-2 data to the ATM latitudes\n",
    "is2_gt2r = is2_gt2r[(is2_gt2r['lat']<atm_l2['Latitude(deg)'].max()) & (is2_gt2r['lat']>atm_l2['Latitude(deg)'].min())]\n",
    "is2_gt2l = is2_gt2l[(is2_gt2l['lat']<atm_l2['Latitude(deg)'].max()) & (is2_gt2l['lat']>atm_l2['Latitude(deg)'].min())]\n",
    "\n",
    "\n",
    "# Set up a map with the flight tracks as overlays\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, Polyline\n",
    "\n",
    "m = Map(\n",
    "    basemap=basemap_to_tiles(basemaps.Esri.WorldImagery),\n",
    "    center=(69.25, 310.35-360),\n",
    "    zoom=10\n",
    ")\n",
    "\n",
    "gt2r_line = Polyline(\n",
    "    locations=[\n",
    "        [is2_gt2r['lat'].min(), is2_gt2r['lon'].max()],\n",
    "        [is2_gt2r['lat'].max(), is2_gt2r['lon'].min()]\n",
    "    ],\n",
    "    color=\"green\" ,\n",
    "    fill=False\n",
    ")\n",
    "m.add_layer(gt2r_line)\n",
    "\n",
    "gt2l_line = Polyline(\n",
    "    locations=[\n",
    "        [is2_gt2l['lat'].min(), is2_gt2l['lon'].max()],\n",
    "        [is2_gt2l['lat'].max(), is2_gt2l['lon'].min()]\n",
    "    ],\n",
    "    color=\"green\" ,\n",
    "    fill=False\n",
    ")\n",
    "m.add_layer(gt2l_line)\n",
    "\n",
    "atm_line = Polyline(\n",
    "    locations=[\n",
    "        [atm_l2['Latitude(deg)'].min(), atm_l2['Longitude(deg)'].max()],\n",
    "        [atm_l2['Latitude(deg)'].max(), atm_l2['Longitude(deg)'].min()]\n",
    "    ],\n",
    "    color=\"orange\" ,\n",
    "    fill=False\n",
    ")\n",
    "m.add_layer(atm_line)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like ATM aligns very closely with the left beam (GT2L), so hopefully the two beams will agree. The terrain over this region is quite rough, so we may expect some differences between ATM and GT2R. ICESat-2 also flew over Sermeq Kujalleq 16 days before ATM, so there might be slight differences due to ice movement.\n",
    "\n",
    "We have looked at how we can quickly access ICESat-2 and airborne lidar data, and process them using `pandas`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Search and open (Landsat) raster imagery from the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now talk about a cloud-optimized approach that requires no downloading to search and access only the subsets of the data we want. Cloud-optimized formats (e.g., [COG](https://www.cogeo.org/), [zarr](https://zarr.readthedocs.io/en/latest/index.html), [parquet](https://parquet.apache.org/)) make reading data two orders of magnitude faster than non-optimized formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud optimized approaches\n",
    "* Organize data as an aggregation of small, independently retrievable objects (e.g., zarr, HDF2, Geotiff in the Cloud)\n",
    "* Allow access to pieces of large objects (e.g., Cloud-Optimized GeoTIFF3, OPeNDAP4 in the Cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with Cloud Optimized GeoTIFF (COG). A COG is a GeoTIFF file with an internal organization that enables more efficient workflows by allowing us to ask for just the parts of a file we need, instead of having to open the entire image or data set (see more at https://www.cogeo.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example url for accessing a band in the cloud from an S3 bucket:\\\n",
    "s3://usgs-landsat/collection02/level-2/standard/oli-tirs/2020/202/025/LC08_L1TP_202025_20190420_20190507_01_T1/LC08_L1TP_202025_20190420_20190507_01_T1_B4.TIF\n",
    "\n",
    "Here is the [User Manual](https://d9-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-2032-Landsat-Commercial-Cloud-Direct-Access-Users-Guide-v2.pdf.pdf) for more information about accessing Landsat S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for Landsat imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To explore and access COG's easily we will use a [SpatioTemporal Asset Catalog (STAC)](https://github.com/radiantearth/stac-spec). The STAC provides a common metadata format to make it easier to index and querry S3 buckets for geospatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up AWS credentials for acquiring images through dask/xarray\n",
    "os.environ[\"AWS_REQUEST_PAYER\"] = \"requester\"\n",
    "\n",
    "# Sets up proper AWS credentials for acquiring data through rasterio\n",
    "aws_session = AWSSession(boto3.Session(), requester_pays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract geometry bounds are extracted from the ICESat-2 KML file used above so that we can perform the Landsat spatial search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract geometry bounds\n",
    "geom = jk.geometry[0]\n",
    "print(geom.bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search for imagery in STAC catalog using the [pystac_client](https://pystac-client.readthedocs.io/en/stable/usage.html) search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search STAC API for Landsat images based on a bounding box, date and other metadata if desired\n",
    "\n",
    "bbox = (geom.bounds[0], geom.bounds[1], geom.bounds[2], geom.bounds[3]) #(west, south, east, north) \n",
    "\n",
    "timeRange = '2019-05-06/2019-05-07'\n",
    "url = 'https://landsatlook.usgs.gov/stac-server'\n",
    "collection = 'landsat-c2l1'\n",
    "    \n",
    "api = pystac_client.Client.open(url)\n",
    "\n",
    "items = api.search(\n",
    "            bbox = bbox,\n",
    "            datetime = timeRange,\n",
    "            limit = 400,\n",
    "            collections=collection\n",
    "        ).get_all_items()\n",
    "    \n",
    "print(f'{len(items)} items')\n",
    "\n",
    "# Write a json file that records our search output\n",
    "gjson_outfile = f'/home/jovyan/Landsat.geojson'\n",
    "items.save_object(gjson_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can include property searches, such as path, row, cloud-cover, as well with the `properties` flag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given a satsearch collection of items (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the geojson file into geopandas and inspect the items we want to collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the geojson file\n",
    "gf = gpd.read_file(gjson_outfile)\n",
    "gf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot search area of interest and frames on a map using Holoviz Libraries (more on these later)\n",
    "cols = gf.loc[:,('id','landsat:wrs_path','landsat:wrs_row','geometry')]\n",
    "footprints = cols.hvplot(geo=True, line_color='k', hover_cols=['landsat:wrs_path','landsat:wrs_row'], alpha=0.3, title='Landsat 8 T1',tiles='ESRI')\n",
    "tiles = gv.tile_sources.CartoEco.options(width=700, height=500) \n",
    "labels = gv.tile_sources.StamenLabels.options(level='annotation')\n",
    "tiles * footprints * labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake all scenes using the intake-STAC library\n",
    "`Intake-STAC` facilitates discovering, exploring, and loading spatio-temporal datasets by providing Intake Drivers for STAC catalogs. This provides a simple toolkit for working with STAC catalogs and for loading STAC assets as `xarray` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_stac_item_collection(items)\n",
    "list(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the metadata and keys for the first scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sceneids = list(catalog)\n",
    "item3 = catalog[sceneids[1]]\n",
    "# item3.metadata\n",
    "for keys in item3.keys():\n",
    "    print (keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the metadata for any of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item3['blue'].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url needed to grab data from the S3 bucket using the intake-STAC catalog\n",
    "item3.blue.metadata['alternate']['s3']['href'] # must use item asset name (blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open and visualize each image using RasterIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "\n",
    "# Retrieve first scene using rio\n",
    "item_url = item3.blue.metadata['alternate']['s3']['href']\n",
    "\n",
    "# Read and plot with grid coordinates \n",
    "with rio.Env(aws_session):\n",
    "    with rio.open(item_url) as src:\n",
    "        fig, ax = plt.subplots(figsize=(9,8))\n",
    "        \n",
    "        # To plot\n",
    "        show(src,1)\n",
    "        \n",
    "        # To open data into a numpy array\n",
    "        profile = src.profile\n",
    "        arr = src.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can open directly into `xarray` using `rasterIO`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating data in Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` and `xarray` have very similar structures and ways of manipulating data, but `pandas` excels with 2-D data and `xarray` is ideal for higher dimension data. `Xarray` introduces labels in the form of dimensions, coordinates and attributes on top of Pandas-like DataFrames.\n",
    "\n",
    "`Xarray` has 2 fundamental data structures:\n",
    "\n",
    "* `DataArray`, which holds single multi-dimensional variables and its coordinates\n",
    "* `Dataset`, which holds multiple variables that potentially share the same coordinates\n",
    "\n",
    "<img src=\"https://xarray-contrib.github.io/xarray-tutorial/_images/xarray-data-structures.png\" width=\"800px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only scratch the surface here on what `xarray` can do. To learn more, there are great `xarray` tutorials here: https://xarray-contrib.github.io/xarray-tutorial/online-tutorial-series/01_xarray_fundamentals.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RasterIO and RioXarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `rasterIO` to easily open into an `xarray` `DataArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rastxr = xr.open_dataarray(item_url,engine='rasterio')\n",
    "rastxr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a `DataSet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rastxr = xr.open_dataset(item_url,engine='rasterio')\n",
    "rastxr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can open using `rioxarray`, which integrates `rasterIO` and `xarray` and is the most efficient way of opening using `rasterIO`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "rastrxr = rxr.open_rasterio(item_url)\n",
    "rastrxr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see `Attributes` have been added to the `xarray` using the same url.\n",
    "\n",
    "Beyond what `xarray` and `rasterIO` provide, `rioxarray` has these added benefits (plus others):\n",
    "* Supports multidimensional datasets such as netCDF\n",
    "* Loads in the CRS, transform, and nodata metadata in standard CF & GDAL locations\n",
    "* Supports masking and scaling data\n",
    "* Loads raster metadata into the attributes\n",
    "\n",
    "For more info: https://corteva.github.io/rioxarray/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another convenient means for opening a lot of raster data into `xarray` is using `dask`. `Xarray` integrates with Dask to support parallel computations and streaming computation on datasets that don’t fit into memory. So this is perfect when you want to process a lot of data. \n",
    "\n",
    "`Dask` divides arrays into many small pieces, called chunks, each of which is presumed to be small enough to fit into memory.\n",
    "\n",
    "Unlike `NumPy`, which has eager evaluation, operations on `dask` arrays are lazy. Operations queue up a series of tasks mapped over blocks, and no computation is performed until you actually ask values to be computed (e.g., to print results to your screen or write to disk). At that point, data is loaded into memory and computation proceeds in a streaming fashion, block-by-block.\n",
    "\n",
    "More on Dask in the Cloud Computing Tools tutorial.\n",
    "\n",
    "To expand our `xarray` toolbox for working with larger data sets that we don't necessarily want entirely in memory, we will start by reading in 3 bands of a Landsat scene to `xarray` using `dask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sceneid = catalog[sceneids[0]]\n",
    "print (sceneid.name)\n",
    "\n",
    "band_names = ['red','green','blue']\n",
    "\n",
    "bands = []\n",
    "\n",
    "# Construct xarray for scene\n",
    "for band_name in band_names:\n",
    "    # Specify chunk size (x,y), Landsat COG is natively in 512 chunks so is best to use this or a multiple\n",
    "    band = sceneid[band_name](chunks=dict(band=1, x=2048, y=2048),urlpath=sceneid[band_name].metadata['alternate']['s3']['href']).to_dask()\n",
    "    band['band'] = [band_name]\n",
    "    bands.append(band)\n",
    "scene = xr.concat(bands, dim='band')\n",
    "scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, it’s best to align [dask chunks](https://docs.dask.org/en/latest/array-best-practices.html) with the way image chunks (typically called “tiles”) are stored on disk or cloud storage buckets. The landsat data is stored on AWS S3 in a tiled Geotiff format where tiles are 512x512, so we should pick some multiple of that, and typically aim for chunk sizes of ~100Mb (although this is subjective)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a way that is similar to `pandas`, we can explore variables easily in `xarray`. We will first work with coordinates (equivalent to indices in `pandas`). Here `x` might often be the longitude (it can be renamed to this actually):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also keep track of arbitrary metadata (called attributes) in the form of a Python dictionary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scene.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply operations over dimensions by name. Here, if we want to slice the data to only have the blue band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.sel(band='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that instead of `loc` (from `pandas`) we are using `sel`, but they function synonymously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical operations (e.g., x - y) vectorize across multiple dimensions (array broadcasting) based on dimension names. Let's determine the mean reflectance for the blue band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.sel(band='blue').mean()#.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can easily use the split-apply-combine paradigm with groupby, which we won't show here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced multi-dimensional read-ins, manipulation and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's open all the bands and multiple days together into an `xarray`. This will be a more complex `xarray` with an extra `'time'` dimension. We have two image in the catalog we can include together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sceneids = list(catalog)\n",
    "sceneids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the time variable first for the `xarray` time dimension. This finds the desired scene IDs in the `geopandas` dataframe we have above and extracts their 'datetime' information. These datetimes get recorded into an `xarray` variable object for 'time'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time variable for time dim\n",
    "time_var = xr.Variable('time',gf.loc[gf.id.isin(sceneids)]['datetime'])\n",
    "time_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will search and collect band names for grabbing each desired band. We will just grab the bands that have 30 m pixels. This provides an example of how you can search data in the STAC catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = []\n",
    "\n",
    "# Get band names for the bands with 30 m resolution from the second scene in our sceneids\n",
    "sceneid = catalog[sceneids[1]]\n",
    "for k in sceneid.keys():\n",
    "    M = getattr(sceneid, k).metadata\n",
    "    if 'eo:bands' in M:\n",
    "        resol = M['eo:bands'][0]['gsd']\n",
    "        print(k, resol)\n",
    "        if resol == 30: \n",
    "            band_names.append(k)\n",
    "            \n",
    "# Add qa band\n",
    "band_names.append('qa_pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now open all of it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to xarray\n",
    "# In xarray dataframe nans are in locations where concat of multiple scenes has expanded the grid (i.e. different path/rows).\n",
    "scenes = []\n",
    "\n",
    "for sceneid in sceneids:\n",
    "    sceneid = catalog[sceneid]\n",
    "    print (sceneid.name)\n",
    "\n",
    "    bands = []\n",
    "\n",
    "    # Construct xarray for scene, open each band, append and concatenate together to create a scene, \n",
    "    # then append and concatenate each scene to create the full dataframe \n",
    "    for band_name in band_names:\n",
    "        band = sceneid[band_name](chunks=dict(band=1, x=2048, y=2048),urlpath=sceneid[band_name].metadata['alternate']['s3']['href']).to_dask()\n",
    "        band['band'] = [band_name]\n",
    "        bands.append(band)\n",
    "    scene = xr.concat(bands, dim='band')\n",
    "    scenes.append(scene)\n",
    "\n",
    "# Concatenate scenes with time variable\n",
    "ls_scenes = xr.concat(scenes, dim=time_var)\n",
    "\n",
    "ls_scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 2 Landsat scenes with all of the bands we are interested in stored in an `xarray`, but you can imagine that this exact code can scale to years worth of data and bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we easily subset one image at a time or the entire `xarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbands = ['blue', 'nir08', 'swir16']\n",
    "\n",
    "# Select the first datetime\n",
    "t = ls_scenes.time.values[1]\n",
    "print (t)\n",
    "\n",
    "# Upper left and lower right coordinates for subsetting to Sermeq Kujalleq area\n",
    "ulx = 300000\n",
    "uly = 7695000\n",
    "lrx = 330000\n",
    "lry = 7670000\n",
    "\n",
    "# Subset xarray to specific time, bands, and x/y locations\n",
    "image = ls_scenes.sel(time=t,band=sbands,y=slice(lry,uly),x=slice(ulx,lrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only the blue band\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "image.sel(band='blue').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data is in UTM 22N, we can reproject to the standard lat/lon coordinate system ([WGS-84](https://epsg.io/4326)) and map with the ICESat-2 and ATM lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.rio.reproject(4326)\n",
    "\n",
    "ISlats = [is2_gt2r['lat'].min(), is2_gt2r['lat'].max()]\n",
    "# ISlons = (is2_gt2r['lon'].max(), is2_gt2r['lon'].min())\n",
    "ISlons = [-55.624,-55.646]\n",
    "\n",
    "ATMlats = [atm_l2['Latitude(deg)'].min(), atm_l2['Latitude(deg)'].max()]\n",
    "# ATMlons = [atm_l2['Longitude(deg)'].max(), atm_l2['Longitude(deg)'].min()]\n",
    "ATMlons = [-55.624,-55.646]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "image.sel(band='blue').plot()\n",
    "plt.plot(ISlons,ISlats,color = 'green')\n",
    "plt.plot(ATMlons,ATMlats,color = 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reprojection to WGS-84 calculated the longitudes to be 6 degrees off, so we shifted the IS2 and ATM data for ease of visualization. This issue only seems to arise with reprojections from some UTM projections and should not be an issue with most data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "Congratulations! You've completed the tutorial. In this tutorial you have gained the skills to: \n",
    "* Search for both optimized and non-optimized cloud data\n",
    "* Open data into `pandas` and `xarray` dataframes/arrays, and \n",
    "* Manipulate, visualize, and explore the data\n",
    "\n",
    "We have concluded by mapping the three data sets together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits\n",
    "* notebook by: Jessica Scheick, Tasha Snow, Zach Fair, Ian Joughin\n",
    "* source material: [is2-nsidc-cloud.py](https://gist.github.com/bradlipovsky/80ab6a7aff3d3524b9616a9fc176065e#file-is2-nsidc-cloud-py-L28) by Brad Lipovsky"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
